{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import CatBoostPruningCallback\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score, make_scorer,\n",
    "                             precision_score, recall_score, roc_auc_score,\n",
    "                             roc_curve)\n",
    "from sklearn.model_selection import (RandomizedSearchCV, StratifiedKFold,\n",
    "                                     train_test_split)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "sns.set()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "RANDOM_SEED = RANDOM_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем решать задачу бинарной классификации, где:  \n",
    "класс 1 соответствует \"плохой\" заявке, которую мы хотим отклонить;  \n",
    "класс 0 же соответствует \"хорошей\" заявке, хотим одобрить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature generation and data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгенерируем дополнительные фичи\n",
    "# Для каждого статуса проверки, мы группируем данные по 'checking_status' и вычисляем стандартное отклонение, медиану и среднее значение 'duration_months' и 'credit_amount'\n",
    "df['check_status_dur_std'] = df.groupby('checking_status')['duration_months'].transform('std')\n",
    "df['check_status_dur_median'] = df.groupby('checking_status')['duration_months'].transform('median')\n",
    "df['check_status_dur_mean'] = df.groupby('checking_status')['duration_months'].transform('mean')\n",
    "\n",
    "# Аналогично для 'credit_amount'\n",
    "df['check_status_credit_am_std'] = df.groupby('checking_status')['credit_amount'].transform('std')\n",
    "df['check_status_credit_am_meadian'] = df.groupby('checking_status')['credit_amount'].transform('median')\n",
    "df['check_status_credit_am_mean'] = df.groupby('checking_status')['credit_amount'].transform('mean')\n",
    "\n",
    "# Аналогичная группировка данных по 'credit_history'\n",
    "df['credit_history_dur_std'] = df.groupby('credit_history')['duration_months'].transform('std')\n",
    "df['credit_history_dur_median'] = df.groupby('credit_history')['duration_months'].transform('median')\n",
    "df['credit_history_dur_mean'] = df.groupby('credit_history')['duration_months'].transform('mean')\n",
    "df['credit_history_credit_am_std'] = df.groupby('credit_history')['credit_amount'].transform('std')\n",
    "df['credit_history_credit_am_median'] = df.groupby('credit_history')['credit_amount'].transform('median')\n",
    "df['credit_history_credit_am_mean'] = df.groupby('credit_history')['credit_amount'].transform('mean')\n",
    "\n",
    "# Дополнительные фичи, которые могут характеризовать условную платёжную нагрузку в единицу времени\n",
    "df['amount_to_duration'] = df['credit_amount'] / df['duration_months']\n",
    "df['installment_mul_duration'] = df['installment_commitment'] * df['duration_months']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1).columns\n",
    "y = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2drop = []\n",
    "target = ['target']\n",
    "filtered_features = [c for c in df.columns if (c not in target and c not in features2drop)]\n",
    "num_features = [c for c in df.columns if c not in target and pd.api.types.is_numeric_dtype(df[c])]\n",
    "cat_features = [c for c in df.columns if c not in target and c not in num_features]\n",
    "assert len(target) + len(num_features) + len(cat_features) + len(features2drop) == len(df.columns)\n",
    "assert len(filtered_features) == len(num_features) + len(cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учитывая малый размер выборки, мы разобьём её только на две части  \n",
    "- *train* - для обучения моделей с использованием кросс-валидации  \n",
    "- *test* - для тестирования лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.25, random_state=RANDOM_STATE, stratify=df[y])\n",
    "print(f'Размер обучающей выборки {train.shape}, это составляет {len(train)/len(df):.0%} данных')\n",
    "print(f'Размер тестовой выборки {test.shape}, это составляет {len(test)/len(df):.0%} данных')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим кастомный скоринг weighted_accuracy.\n",
    "\n",
    "Описание данных сообщает нам валюту счёта - `Deutsche Mark`.  \n",
    "Учитывая низкий уровень инфляции (как следствие - низкий уровень процентных ставок по кредитным продуктам), одобрение \"плохой\" заявки может нести существенные финансовые потери.  \n",
    "В этой связи мы будем сильнее штрафовать модель за FN (то есть одобрение \"плохой\" заявки) будем использовать вес -10.  \n",
    "Вес верного предсказания отрицательного класса (TN) будет 2, мы хотим одобрять \"хорошие\" заявки и зарабатывать на этом.  \n",
    "Вес неверного предсказания положительного класса (FP) будет -1, мы не хотим терять потенциал и отклонять \"хорошие\" заявки.  \n",
    "Вес верно отклонённой заявки (TP) будет равен 0.  \n",
    "\n",
    "Таким образом мы будем стараться максимизировать показатель `weighted_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom scoring function for evaluating model accuracy with weighted penalties.\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): Ground truth target values.\n",
    "        y_pred (array-like): Predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        float: Weighted accuracy score, representing the proportion of correctly classified instances with penalties applied.\n",
    "\n",
    "    Notes:\n",
    "        The cost matrix is defined as follows:\n",
    "            - Cost of predicting class 0 when true label is 0: 2\n",
    "            - Cost of predicting class 0 when true label is 1: -10\n",
    "            - Cost of predicting class 1 when true label is 0: -1\n",
    "            - Cost of predicting class 1 when true label is 1: 0\n",
    "    \"\"\"\n",
    "\n",
    "    cost_matrix = np.array([\n",
    "        [2, -1],  # weight for actual class 0\n",
    "        [-10, 0]  # weight for actual class 1\n",
    "    ])\n",
    "\n",
    "    costs = cost_matrix[y_true, y_pred]\n",
    "\n",
    "    return round(np.sum(costs) / len(costs), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_accuracy_scorer = make_scorer(weighted_accuracy, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rs(model, grid_params, n_iter, x_train, y_train, verbose=0, random_state=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    Hyperparameter Tuning with Randomized Grid Search.\n",
    "\n",
    "    This function performs hyperparameter tuning using RandomizedSearchCV from scikit-learn.\n",
    "    It returns the best estimator and the search object itself.\n",
    "\n",
    "        Args:\n",
    "        model (object): The base estimator to be tuned.\n",
    "        grid_params (dict): Dictionary of parameters to be searched over.\n",
    "        n_iter (int): Number of random samples drawn from the parameter space to perform the search.\n",
    "        x_train (array-like): Training data.\n",
    "        y_train (array-like): Target variable data.\n",
    "        verbose (int, optional): Verbosity level. Can be 0 or 1. Defaults to 0.\n",
    "        random_state (int, optional): Random seed for reproducibility. Defaults to RANDOM_STATE.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the best estimator and the search object itself.\n",
    "\n",
    "    Notes:\n",
    "        The grid search is performed with a stratified k-fold cross-validation strategy using 5 folds.\n",
    "        The scoring metric used is the weighted accuracy, which takes into account the cost of misclassifying each instance.\n",
    "        The search process can be verbose, printing out the best parameters found at each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    print('Performing grid search...')\n",
    "    print('Hyperparameters to be evaluated:')\n",
    "    pprint(grid_params)\n",
    "    print()\n",
    "\n",
    "    clf_rnd_gs = RandomizedSearchCV(\n",
    "        model,\n",
    "        grid_params,\n",
    "        random_state=random_state,\n",
    "        n_iter=n_iter,\n",
    "        cv=5,\n",
    "        verbose=verbose,\n",
    "        n_jobs=-1,\n",
    "        scoring=weighted_accuracy_scorer,\n",
    "    )\n",
    "\n",
    "    clf_rnd_gs.fit(x_train, y_train)\n",
    "\n",
    "    print('Best parameters:')\n",
    "    for elem in sorted(clf_rnd_gs.best_params_):\n",
    "        print(f'{elem}: {clf_rnd_gs.best_params_.get(elem)}')\n",
    "\n",
    "    return (clf_rnd_gs.best_estimator_, clf_rnd_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_catboost(trial, train, valid, cf=cat_features):\n",
    "    \"\"\"\n",
    "    Optimizes and trains a CatBoostClassifier using Optuna for hyperparameter tuning.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    trial : optuna.trial.Trial\n",
    "        A single trial object from Optuna, used to suggest hyperparameters for the model.\n",
    "\n",
    "    train : tuple (X_train, y_train)\n",
    "        Training data. `X_train` is the feature matrix and `y_train` is the target array.\n",
    "\n",
    "    valid : tuple (X_valid, y_valid)\n",
    "        Validation data. `X_valid` is the feature matrix for validation, and `y_valid` is the target array for validation.\n",
    "\n",
    "    cf : list, optional\n",
    "        List of categorical feature indices or column names to be used by CatBoost, by default `cat_features`.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    y_pred : array-like\n",
    "        Predicted labels for the validation data.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The function suggests hyperparameters for learning rate, L2 regularization, column sample by level, class weights,\n",
    "      depth of the tree, and boosting type using Optuna's `trial.suggest_*` methods.\n",
    "    - Depending on the selected `bootstrap_type`, the function also suggests values for `bagging_temperature` or `subsample`.\n",
    "    - The classifier is fitted with early stopping (50 rounds) based on validation performance.\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, y_train = train\n",
    "    X_valid, y_valid = valid\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3),\n",
    "        'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 2, 100),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.01, 0.75),\n",
    "\n",
    "        'auto_class_weights': trial.suggest_categorical('auto_class_weights', ['SqrtBalanced', 'Balanced', 'None']),\n",
    "        'depth': trial.suggest_int('depth', 3, 12),\n",
    "\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "        'used_ram_limit': '14gb',\n",
    "    }\n",
    "\n",
    "\n",
    "    if params['bootstrap_type'] == 'Bayesian':\n",
    "        params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 10, 20)\n",
    "\n",
    "    elif params['bootstrap_type'] == 'Bernoulli':\n",
    "        params['subsample'] = trial.suggest_float('subsample', 0.1, 0.75)\n",
    "\n",
    "    clf = CatBoostClassifier(\n",
    "        **params,\n",
    "        random_state=RANDOM_STATE,\n",
    "        cat_features=cf,\n",
    "        verbose=0,\n",
    "        eval_metric='AUC',\n",
    "        )\n",
    "\n",
    "    clf.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=(X_valid, y_valid),\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for optimizing a CatBoostClassifier using Optuna and cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    trial : optuna.trial.Trial\n",
    "        A single trial object from Optuna, used to suggest hyperparameters for the CatBoost model.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    result : float\n",
    "        The mean weighted accuracy score from cross-validation.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The function uses Stratified K-Fold cross-validation with `n_splits=3` to evaluate the model performance.\n",
    "    - Features are selected from the `train` dataset using `filtered_features`, with the target column excluded.\n",
    "    - For each fold, the function fits the CatBoost model using the `fit_catboost` function and records the weighted accuracy score for the validation set.\n",
    "    - The final result is the mean of the scores from all the folds, which is used as the objective to be minimized or maximized by Optuna.\n",
    "    \"\"\"\n",
    "\n",
    "    n_splits = 3\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    X_train = train[filtered_features].drop(target, axis=1, errors=\"ignore\")\n",
    "    y_train = train[target]\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X_train, y_train):\n",
    "        train_data = X_train.iloc[train_idx, :], y_train.iloc[train_idx]\n",
    "        valid_data = X_train.iloc[valid_idx, :], y_train.iloc[valid_idx]\n",
    "\n",
    "        y_pred = fit_catboost(trial, train_data, valid_data)\n",
    "        scores.append(weighted_accuracy(valid_data[1], y_pred))\n",
    "\n",
    "    result = np.mean(scores)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(actual_classes, predicted_classes, predicted_proba):\n",
    "    \"\"\"\n",
    "    Calculate various metrics for a classification model.\n",
    "\n",
    "    Args:\n",
    "        actual_classes (numpy.ndarray): The true class labels.\n",
    "        predicted_classes (numpy.ndarray): The predicted class labels.\n",
    "        predicted_proba (numpy.ndarray): The predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following metrics:\n",
    "            `rocauc`: The receiver operating characteristic area under the curve (ROC-AUC) score.\n",
    "            `accuracy`: The accuracy score, i.e., the proportion of correctly classified instances.\n",
    "            `precision`: The precision score, i.e., the ratio of true positives to the sum of true positives and false positives.\n",
    "            `recall`: The recall score, i.e., the ratio of true positives to the sum of true positives and false negatives.\n",
    "            `f1`: The F1 score, which is the harmonic mean of precision and recall.\n",
    "            `weighted_acc`: The custom weighted accuracy score.\n",
    "    \"\"\"\n",
    "    rocauc = roc_auc_score(actual_classes, predicted_proba[:,1])\n",
    "    accuracy = accuracy_score(actual_classes, predicted_classes)\n",
    "    precision = precision_score(actual_classes, predicted_classes)\n",
    "    recall = recall_score(actual_classes, predicted_classes)\n",
    "    f1 = f1_score(actual_classes, predicted_classes)\n",
    "    weighted_acc = weighted_accuracy(actual_classes, predicted_classes)\n",
    "\n",
    "    return (rocauc, accuracy, precision, recall, f1, weighted_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm_rocauc(actual_classes, predicted_classes, predicted_proba, sorted_labels=['Good', 'Bad']):\n",
    "    \"\"\"\n",
    "    Plot the confusion matrix and ROC curve for a classification model.\n",
    "\n",
    "    Args:\n",
    "        actual_classes (numpy.ndarray): The true class labels.\n",
    "        predicted_classes (numpy.ndarray): The predicted class labels.\n",
    "        predicted_proba (numpy.ndarray): The predicted probabilities.\n",
    "        sorted_labels (list[str], optional): A list of labels to use for the confusion matrix and ROC curve. Defaults to [\"Good\", \"Bad\"].\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    matrix = confusion_matrix(actual_classes, predicted_classes)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(\n",
    "        matrix,\n",
    "        annot=True,\n",
    "        xticklabels=sorted_labels,\n",
    "        yticklabels=sorted_labels,\n",
    "        cmap='gnuplot',\n",
    "        fmt='g',\n",
    "    )\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    probabilities_one = predicted_proba[:, 1]\n",
    "\n",
    "    sns.set(rc={'figure.figsize': (9, 6)})\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(actual_classes, probabilities_one)\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(fpr, tpr)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "    plt.title('ROC')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(actual_classes, predicted_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_val_predict(model, kfold, X, y):\n",
    "    \"\"\"\n",
    "    Perform stratified k-fold cross-validation and predict classes using the given model.\n",
    "\n",
    "    Args:\n",
    "        model (BaseEstimator): The classification model to use for prediction.\n",
    "        kfold (StratifiedKFold): A StratifiedKFold object for splitting the data into training and testing sets.\n",
    "        X (pd.DataFrame): The feature matrix.\n",
    "        y (pd.Series): The target variable.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the ROC-AUC score, weighted accuracy, and other performance metrics.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model_ = deepcopy(model)\n",
    "\n",
    "    no_classes = len(np.unique(y))\n",
    "\n",
    "    actual_classes = np.empty([0], dtype=int)\n",
    "    predicted_classes = np.empty([0], dtype=int)\n",
    "    predicted_proba = np.empty([0, no_classes])\n",
    "\n",
    "    for train_ndx, test_ndx in kfold.split(X, y):\n",
    "        train_X, train_y, test_X, test_y = (\n",
    "            X.iloc[train_ndx],\n",
    "            y.iloc[train_ndx],\n",
    "            X.iloc[test_ndx],\n",
    "            y.iloc[test_ndx],\n",
    "        )\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "\n",
    "        model_.fit(train_X, train_y)\n",
    "        predicted_classes = np.append(predicted_classes, model_.predict(test_X))\n",
    "\n",
    "        try:\n",
    "            predicted_proba = np.append(\n",
    "                predicted_proba, model_.predict_proba(test_X), axis=0\n",
    "            )\n",
    "        except Exception:\n",
    "            predicted_proba = np.append(\n",
    "                predicted_proba,\n",
    "                np.zeros((len(test_X), no_classes), dtype=float),\n",
    "                axis=0,\n",
    "            )\n",
    "\n",
    "    plot_cm_rocauc(actual_classes, predicted_classes, predicted_proba)\n",
    "\n",
    "    cur_metrics = calc_metrics(actual_classes, predicted_classes, predicted_proba)\n",
    "\n",
    "    print('Train data StratifiedKFold CV:')\n",
    "    print(f'ROC-AUC {cur_metrics[0]:.3f}\\nWeighted_accuracy {cur_metrics[-1]:.3f}')\n",
    "\n",
    "    return cur_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_display_results(name, metrics):\n",
    "    \"\"\"\n",
    "    Accumulate training results to a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        name (str): The name or identifier for the current run.\n",
    "        metrics (tuple): A tuple containing the performance metrics.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Notes:\n",
    "        This function adds a new row to the `results` DataFrame with the given name and metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    global results\n",
    "\n",
    "    results.loc[name] = [*metrics]\n",
    "    display(results)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'ROC-AUC': [],\n",
    "                        'Accuracy': [],\n",
    "                        'Precision': [],\n",
    "                        'Recall': [],\n",
    "                        'F1_score' : [],\n",
    "                        'Weighted_accuracy': []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учитывая малый размер выборки, начнём с простой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(steps=[\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('one-hot', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False))\n",
    "])\n",
    "\n",
    "pre_processor = ColumnTransformer(transformers=[\n",
    "    ('number', num_pipeline, num_features),\n",
    "    ('category', cat_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocess', pre_processor),\n",
    "    ('classify', LogisticRegression(random_state=RANDOM_STATE))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "metrics = cross_val_predict(lr_pipeline, kfold, train[X], train[y]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_display_results('Baseline_LogReg', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_lr = {\n",
    "    'classify__C': np.logspace(-4, 4, 10),\n",
    "    'classify__class_weight': ['balanced', None],\n",
    "    'classify__max_iter': range(500, 5001, 500),\n",
    "    'classify__penalty': ['l2', 'l1', 'elasticnet']\n",
    "}\n",
    "\n",
    "n_iter = 500\n",
    "\n",
    "best_lr_model, lr_rs = rs(lr_pipeline, grid_params_lr, n_iter, train[X], train[y].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/Logistic_regression.pkl', 'wb') as file:\n",
    "    pickle.dump(best_lr_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = cross_val_predict(best_lr_model, kfold, train[X], train[y]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_display_results('Logistic_regression', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processor_rf = ColumnTransformer(transformers=[\n",
    "    ('category', cat_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocess', pre_processor_rf),\n",
    "    ('classify', RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "grid_params_rf = {\n",
    "    'classify__n_estimators': range(50, 1000, 100),\n",
    "    'classify__max_depth': range(1, 16, 2),\n",
    "    'classify__min_samples_leaf': [10, 25, 50, 75, 100],\n",
    "    'classify__criterion': ['entropy', 'gini'],\n",
    "    'classify__max_features': [None, 0.75, 0.5, 0.25, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "n_iter = 100\n",
    "\n",
    "best_rf_model, rf_rs = rs(rf_pipeline, grid_params_rf, n_iter, train[X], train[y].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/Random_forest.pkl', 'wb') as file:\n",
    "    pickle.dump(best_rf_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = cross_val_predict(best_rf_model, kfold, train[X], train[y]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_display_results('Random_forest', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'cat_features': cat_features,\n",
    "    'loss_function': 'Logloss',\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_cb = {\n",
    "    'n_estimators': range(200, 1001, 200),\n",
    "    'learning_rate': [0.001, 0.01, 0.025, 0.05, 0.1, 0.2, 0.3],\n",
    "    'depth': [1, 2, 3, 4, 8, 12],\n",
    "    'l2_leaf_reg': np.linspace(2, 30, 10, dtype=int),\n",
    "    'colsample_bylevel': [x / 100 for x in range(10, 51, 10)] + [None],\n",
    "    'subsample': [x / 100 for x in range(50, 100, 15)] + [None],\n",
    "    'bootstrap_type': ['Bayesian', 'Bernoulli', 'MVS'],\n",
    "    'auto_class_weights': ['Balanced', None]\n",
    "}\n",
    "\n",
    "n_iter = 100\n",
    "\n",
    "best_cb_model, cb_rs = rs(CatBoostClassifier(**params), grid_params_cb, n_iter, train[X], train[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/Catboost.pkl', 'wb') as file:\n",
    "    pickle.dump(best_cb_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = cross_val_predict(best_cb_model, kfold, train[X], train[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_display_results('Catboost', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=300,\n",
    "    n_jobs=-1,\n",
    "    show_progress_bar=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(study.best_trial.value, 3))\n",
    "pprint(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = study.best_trial.value\n",
    "best_params = study.best_trial.params\n",
    "best_params.update({\n",
    "    'cat_features': cat_features,\n",
    "    'verbose': 0,\n",
    "    'random_state': RANDOM_STATE\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['l2_leaf_reg', 'colsample_bylevel', 'bagging_temperature', 'depth', 'bootstrap_type', 'subsample', 'learning_rate', 'auto_class_weights']\n",
    "optuna.visualization.plot_slice(study,\n",
    "                                params=params,\n",
    "                                target_name = 'weighted_ccuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Важность параметров\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_opt = CatBoostClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = cross_val_predict(cb_opt, kfold, train[X], train[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/Catboost_opt.pkl', 'wb') as file:\n",
    "    pickle.dump(cb_opt, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_display_results('Catboost_optuna', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DummyClassifier(strategy='uniform', random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.fit(train[X], train[y])\n",
    "print(f'Weighted accuracy for dummy classifier (uniform) = {weighted_accuracy(train[y].values.ravel(), dc.predict(train[X]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель логистической регрессии показывает лучший результат `wieghted_accuracy` в совокупности с максимальным `f1_score`.  \n",
    "Проверим модель Logistic_regression на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/Logistic_regression.pkl', 'rb') as file:\n",
    "    best_model = pickle.load(file)\n",
    "\n",
    "best_model.fit(train[X], train[y])\n",
    "pred = best_model.predict(test[X])\n",
    "pred_proba = best_model.predict_proba(test[X])\n",
    "\n",
    "print(classification_report(test[y], pred))\n",
    "\n",
    "roc_auc, accuracy, precision, recall, f1, weighted_acc = calc_metrics(test[y], pred, pred_proba)\n",
    "\n",
    "print(f'{\"lr\"} | {roc_auc = :.3f} | {weighted_acc = :.3f}')\n",
    "\n",
    "matrix = confusion_matrix(test[y], pred)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(\n",
    "    matrix,\n",
    "    annot=True,\n",
    "    xticklabels=['Good', 'Bad'],\n",
    "    yticklabels=['Good', 'Bad'],\n",
    "    cmap='gnuplot',\n",
    "    fmt='g',\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики классификации на тестовой выборке не притерпели значительного уменьшения, что свидетельствует об отстутствии переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществим подбор порога на обучающей выборке с максимизацией weighted_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_wa = float('-inf')\n",
    "best_thr = 0.5\n",
    "with open('../models/Logistic_regression.pkl', 'rb') as file:\n",
    "    best_model = pickle.load(file)\n",
    "\n",
    "best_model.fit(train[X], train[y])\n",
    "pred_proba = best_model.predict_proba(train[X])\n",
    "thrs = np.unique(pred_proba[:, 1])\n",
    "scores = []\n",
    "\n",
    "for thr in thrs:\n",
    "    pred = (pred_proba[:, 1] >= thr).astype(int)\n",
    "    wa = weighted_accuracy(train[y], pred)\n",
    "    if wa > best_wa:\n",
    "        best_wa = wa\n",
    "        best_thr = thr\n",
    "print(f'{best_wa = }, {best_thr = }')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/Logistic_regression.pkl', 'rb') as file:\n",
    "    best_model = pickle.load(file)\n",
    "\n",
    "best_model.fit(train[X], train[y])\n",
    "pred_proba = best_model.predict_proba(test[X])\n",
    "pred = (pred_proba[:, 1] >= best_thr).astype(int)\n",
    "\n",
    "print(classification_report(test[y], pred))\n",
    "\n",
    "roc_auc, accuracy, precision, recall, f1, weighted_acc = calc_metrics(test[y], pred, pred_proba)\n",
    "\n",
    "print(f'lr with optimized thr | {roc_auc = :.3f} | {weighted_acc = :.3f}')\n",
    "\n",
    "matrix = confusion_matrix(test[y], pred)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(\n",
    "    matrix,\n",
    "    annot=True,\n",
    "    xticklabels=['Good', 'Bad'],\n",
    "    yticklabels=['Good', 'Bad'],\n",
    "    cmap='gnuplot',\n",
    "    fmt='g',\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(\n",
    "    best_model,\n",
    "    test[X],\n",
    "    test[y],\n",
    "    scoring=weighted_accuracy_scorer,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_repeats=50\n",
    ")\n",
    "importance_df = pd.DataFrame({'feature': test[X].columns, 'importance': result.importances_mean})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "display(importance_df[:15])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее важными являются признаки, описывающие состояние текущего и накопительного счетов, возраст, цель кредита, а также некоторые сгенерированные признаки.  \n",
    "\n",
    "Для повышения качества рекомендуется обогатить датасет следующими данными:  \n",
    "\n",
    "1. Кредитная история:  \n",
    "    Суммарный показатель кредитоспособности, основанный на истории предыдущих кредитов, платежей, задолженностей.  \n",
    "    Прямо отражает, насколько ответственно заявитель относится к финансовым обязательствам.  \n",
    "\n",
    "2. Соотношение долга к доходу (Debt-to-Income Ratio, DTI):  \n",
    "    Процент ежемесячного дохода, который идет на погашение долгов (кредиты, ипотека, алименты и др.).  \n",
    "    Показывает финансовую нагрузку на заявителя и его способность погашать новый кредит.  \n",
    "    Наш датасет обладает аналогичным признаком по запрашиваемому займу,  \n",
    "    может быть полезным показатель DTI по всем имеющимся обязательствам.\n",
    "\n",
    "3.  Стаж работы и доход:  \n",
    "    Текущее место работы, должность, уровень  дохода.  \n",
    "    Стабильный доход и работа - ключевые факторы, влияющие на способность погашать кредит."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
